{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGI1QAVHRW4f",
    "outputId": "fb7ef941-b1c1-49cf-f2f5-d13cd6c45a6e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/gdrive/MyDrive/iberlef/IberLEF2023"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vglI7gnDRdOT",
    "outputId": "e1bdd0fd-85fd-47c0-f0db-61721cee0813"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/gdrive/MyDrive/iberlef/IberLEF2023\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! git status"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtQGKIpGRvu_",
    "outputId": "dc5672a6-55dc-4718-e4ee-d92ecb3c300e"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Refresh index: 100% (11/11), done.\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\t\u001B[32mnew file:   .gitignore\u001B[m\n",
      "\t\u001B[32mnew file:   README.md\u001B[m\n",
      "\t\u001B[32mnew file:   data/full_data/cleaned/cleaned_full_data.csv\u001B[m\n",
      "\t\u001B[32mnew file:   data/full_data/full_data.csv\u001B[m\n",
      "\t\u001B[32mnew file:   data/practise_data/cleaned/cleaned_development_test.csv\u001B[m\n",
      "\t\u001B[32mnew file:   data/practise_data/cleaned/cleaned_development_train.csv\u001B[m\n",
      "\t\u001B[32mnew file:   data/practise_data/development_test.csv\u001B[m\n",
      "\t\u001B[32mnew file:   data/practise_data/development_train.csv\u001B[m\n",
      "\t\u001B[32mnew file:   data/synthetic_data/synthetic_data.csv\u001B[m\n",
      "\t\u001B[32mnew file:   preprocess.ipynb\u001B[m\n",
      "\t\u001B[32mnew file:   req.txt\u001B[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001B[31mpolitibeto_pretrain.ipynb\u001B[m\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pretraining PolitiBETO on this year's IberLEF shared task dataset that has been cleaned with [preprocess.ipynb](https://github.com/Abbywpy/IberLEF2023/blob/main/preprocess.ipynb)."
   ],
   "metadata": {
    "id": "eik3Ic4USOiE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./data/full_data/cleaned/cleaned_full_data.csv\"):\n",
    "    df = pd.read_csv(\"./data/full_data/cleaned/cleaned_full_data.csv\")\n",
    "    df[\"cleaned_tweet\"] = df[\"cleaned_tweet\"].astype(str)\n",
    "    df_tweets = pd.DataFrame(df[\"cleaned_tweet\"])\n",
    "    df_tweets.to_csv(\"./data/full_data/cleaned/cleaned_tweets_only.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# replace the path for according to the data you want to use\n",
    "datafile = \"cleaned_tweets_only.csv\"\n",
    "dataset = load_dataset('csv', data_files=os.path.join(\"./data/full_data/cleaned\", datafile))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "ulecAfLPSEmy",
    "outputId": "5eadf683-0af0-4666-c4d8-80b3e9838690"
   },
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/michelle/.cache/huggingface/datasets/csv/default-1efde2b9b06a2be3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 427.12it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 142.55it/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]/Users/michelle/Desktop/cl/ml4nlp2/iberlef/iberenv/lib/python3.8/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/michelle/.cache/huggingface/datasets/csv/default-1efde2b9b06a2be3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.10it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\" this is only to test if the code works, don't use in actual training \"\"\"\n",
    "# from datasets import DatasetDict\n",
    "#\n",
    "# print(type(dataset))\n",
    "# dataset = dataset[\"train\"].select(range(10))\n",
    "#\n",
    "# dataset = DatasetDict({\"train\": dataset})\n",
    "#\n",
    "# print(type(dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cleaned_tweet': '¡Feliz 28 de Febrero a Todas Las Andaluzas Y Andaluces! . Por Una Andalucía Donde El presente, Y El Futuro, sea Sinónimo de Derechos, de Igualdad Plena, de Trabajo Estable Y con Condiciones Dignas . Una Andalucía de Nuevas Oportunidades, de Esperanza.'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "model_checkpoint = \"nlp-cimat/politibeto\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"cleaned_tweet\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "id": "ZxqBCVO_S0sz"
   },
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pretrained_politibeto/\" + datafile[:-4].split(\"_\",1)[1],\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,  # hyperparameters the same as mentioned in Villa-Cueva et al. (2022)\n",
    "    per_device_train_batch_size=128,\n",
    "    learning_rate=5e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/3 : < :, Epoch 1/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=3, training_loss=1.506382902463277, metrics={'train_runtime': 38.2203, 'train_samples_per_second': 0.785, 'train_steps_per_second': 0.078, 'total_flos': 956179090800.0, 'train_loss': 1.506382902463277, 'epoch': 3.0})"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
